#!/home/savoirvi/bin/mksh
# Ypnose - http://ywstd.fr
# Copyright (c) 2013-2015, Ypnose - All rights reserved.
# This project is under BSD (3-Clause) License
# See LICENSE for license details.
#set -x
RAC="$1"

function prynt_err {
	print -u2 "ERR:" "$@"
	exit 1
}

function parse_config {
	if [[ -r ${RAC}/wswsh.conf && -r ${RAC}/includes/layout ]]; then
		. "${RAC}/wswsh.conf" && . "${RAC}/includes/layout"
	else
		prynt_err "Missing wswsh.conf / layout"
	fi
}

function get_structure {
	if [[ ! -d ${RAC}/src ]]; then
		prynt_err "src doesn't exist"
	fi
	[[ ! -d ${RAC}/dest ]] && mkdir "${RAC}/dest"

	if [[ -n $(find "${RAC}/src" -type d -print) ]]; then
		# The following line works with GNU find:
		# find "${RAC}/src" -type d -printf "dest/%P\0" | xargs -0 mkdir -p
		# I finally decided to write lines "compatible" with {Mir,Open}BSD. Here we go:
		cd "${RAC}/dest"
		( cd ../src; find . -type d -print0 ) | xargs -0 mkdir -p
		cd ..
	else
		print "No directory found. Nothing to create"
	fi
}

function get_interp {
	case $INTERP in
		# We can't use 'print " | "$0' because the function is used two times.
		*ahrf*) function pagetit { awk '/^[\t ]*:/{gsub(/^[\t ]*:[\t ]*|[\t ]*:[\t ]*$/,"");print $0;exit}' "$1"; };;
		smu) function pagetit { awk '/\#/{gsub(/^[\t ]*#[\t ]*/,"");print $0;exit}' "$1"; };;
		*) function pagetit { awk '/<h1>/{gsub(/^[\t ]*<h1>[\t ]*|[\t ]*<\/h1>.*/,"");print $0;exit}' "$1"; };;
	esac
}

function pagetit_html { awk '/<h1>/{gsub(/^[\t ]*<h1>[\t ]*|[\t ]*<\/h1>.*/,"");print $0;exit}' "$1"; }

function gen_page {
	if [[ -n $CSSF && -r ${RAC}/src/${CSSF} ]]; then
		# Launch layout custom stylesheet
		CSSV=1
		cp "${RAC}/src/${CSSF}" "${RAC}/dest/${CSSF}"
	fi

	if [[ -n $INTERP && -z $(whence -p $INTERP) ]]; then
		prynt_err "$INTERP not found"
	fi
	print "Generating pages..."
	get_interp
	cd "$RAC"
	find "src" -type f -iname "*.${EXT:-txt}" | while IFS=$'\n' read -r FILE; do
		FILENOSRC="${FILE#*/}"
		FILENOEXT="${FILENOSRC%%.*}"
		FILEXPORT="dest/${FILENOEXT}.html"
		FILETIT="$(pagetit "$FILE")"
		page_head >"$FILEXPORT"
		"${INTERP:-cat}" "$FILE" >>"$FILEXPORT"
		RET=$?
		if (( RET != 0 )); then
			prynt_err "Generating $FILE failed"
		fi
		page_foot >>"$FILEXPORT"
		(( COPY == 1 )) && cp "src/${FILENOSRC}" "dest/${FILENOSRC}"
	done

	find "src" -type f -iname “*.wshtml” | while IFS=$'\n' read -r FILE; do
		FILENOSRC="${FILE#*/}"
		FILENOEXT="${FILENOSRC%%.*}"
		FILEXPORT="dest/${FILENOEXT}.html"
		FILETIT="$(pagetit_html "$FILE")"
		page_head >"$FILEXPORT"
		cat "$FILE" >>"$FILEXPORT"
		RET=$?
		if (( RET != 0 )); then
			prynt_err "Generating $FILE failed"
		fi
		page_foot >>"$FILEXPORT"
	done
	# RSS / Atom
	if (( FEED == 1 )); then
		[[ -n $ARTD && ! -d $ARTD ]] && prynt_err "The article directory is missing!"
		# XML date, emulates $(date --rfc-3339=seconds) from GNU date.
		RDAT=$(LC_ALL=C date "+%Y-%m-%dT%H:%M:%SZ")
		RSSF="dest/${RSSDIR}atom.xml"
		# Tip: date format -> year-month-day
		SORD="$(find "${ARTD:-src/blog/}" -mindepth 2 -type f -iname "*.${EXT:-txt}" | while IFS=$'\n' read -r ART; do \
			awk '/<!--[\t ]*DATE/{gsub(/^[\t ]*<!--[\t ]*DATE *: *|[\t ]*-->.*/,"");printf "%s",$0;exit}' $ART; \
			print " $ART"; done | sort -nr | awk '{gsub(/201[2-8]-[0-1][0-9]-[0-3][0-9] /,"");print}')"
		if [[ -z $SORD ]]; then
			prynt_err "No articles found inside ${ARTD:-src/blog/}"
		fi
		gen_site_xml >"$RSSF"
		print -- "$SORD" | while IFS=$'\n' read -r FILE; do
			# Don't need to enable a specific hour, let's assume I wrote the pages at midday.
			RDADAT="$(awk '/<!--[\t ]*DATE/{gsub(/^[\t ]*<!--[\t ]*DATE *: *|[\t ]*-->.*/,"");print $0"T12:00:00Z";exit}' $FILE)"
			RSSDES="$(awk '/<!--[\t ]*DESC/{gsub(/^[\t ]*<!--[\t ]*DESC *: *|[\t ]*-->.*/,"");print $0;exit}' $FILE)"
			RSSTNOSRC="${FILE#*/}"
			RSSTNOEXT="${RSSTNOSRC%%.*}"
			FILETIT="$(pagetit "$FILE")"
			xml_content >>"$RSSF"
		done
		print '</feed>' >>"$RSSF"
	fi

	# We copy existing *.html files from src to dest.
	find "src" -type f -iname "*.html" | while IFS=$'\n' read -r LINEH; do
		if [[ -r dest/${LINEH#*/} ]]; then
			print "dest/${LINEH#*/} already exists"
			continue
		fi
		cp -- "$LINEH" "dest/${LINEH#*/}"
	done

	cd ..
	TOT=$(find "${RAC}/dest" -type f | wc -l)
	print "Generated $TOT files"
}

if [[ -z $1 ]]; then
	print "usage: ${0##*/} [website_root]"
	exit
fi

parse_config
get_structure
gen_page

exit
